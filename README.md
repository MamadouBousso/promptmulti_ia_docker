# PromptMulti_IA Docker

Un assistant multi-IA intelligent d√©velopp√© avec Flask et une interface web moderne utilisant Tailwind CSS, int√©grant les APIs OpenAI (GPT-4o), Claude (Anthropic) et Groq (Llama) pour des r√©ponses intelligentes et comparatives. **Version Dockeris√©e pour un d√©ploiement facile.**

## üìã Description

PromptMulti_IA Docker est une application web qui permet aux utilisateurs d'interagir avec plusieurs assistants IA via un formulaire textuel. L'application supporte trois fournisseurs d'IA majeurs et permet de comparer leurs r√©ponses en temps r√©el. **L'application est enti√®rement containeris√©e avec Docker pour un d√©ploiement simplifi√©.**

## üöÄ Fonctionnalit√©s

- **Interface Web Moderne** : Interface utilisateur responsive avec Tailwind CSS
- **Multi-IA Support** : Int√©gration OpenAI (GPT-4o), Claude (Anthropic) et Groq (Llama)
- **Comparaison en Temps R√©el** : Compare les r√©ponses des trois mod√®les simultan√©ment
- **Rendu Markdown** : Affichage riche avec support complet du formatage markdown
- **S√©lection de Mod√®les** : Choix sp√©cifique des mod√®les Llama pour Groq
- **Formulaire Interactif** : Zone de saisie pour les prompts textuels
- **API REST Compl√®te** : Endpoints pour chaque fournisseur d'IA
- **Gestion des Erreurs** : Interface utilisateur avec gestion des erreurs robuste
- **Indicateur de Chargement** : Feedback visuel pendant la g√©n√©ration
- **Architecture Modulaire** : Structure organis√©e avec s√©paration des responsabilit√©s
- **Docker Ready** : Containerisation compl√®te avec Docker et Docker Compose
- **Gestion des D√©pendances** : Utilisation de uv pour une installation rapide

## üõ†Ô∏è Technologies Utilis√©es

- **Backend** : Flask (Python)
- **Frontend** : HTML5, JavaScript, Tailwind CSS
- **IA** : 
  - OpenAI API (GPT-4o)
  - Anthropic API (Claude 3.5 Sonnet)
  - Groq API (Llama 3.1, Llama 4 Scout)
- **Markdown** : marked.js pour le rendu
- **Gestion des D√©pendances** : uv
- **Variables d'Environnement** : python-dotenv
- **Architecture** : Pattern MVC (Model-View-Controller)
- **Containerisation** : Docker, Docker Compose

## üìÅ Structure du Projet

```
promptmulti_ia_docker/
‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îú‚îÄ‚îÄ application/     # Couche application (logique m√©tier)
‚îÇ   ‚îú‚îÄ‚îÄ domaine/         # Couche domaine (entit√©s et r√®gles m√©tier)
‚îÇ   ‚îî‚îÄ‚îÄ infrastructure/  # Couche infrastructure (base de donn√©es, API externes)
‚îÇ       ‚îú‚îÄ‚îÄ openai_client.py   # Client pour l'API OpenAI
‚îÇ       ‚îú‚îÄ‚îÄ claude_client.py   # Client pour l'API Claude
‚îÇ       ‚îî‚îÄ‚îÄ groq_client.py     # Client pour l'API Groq
‚îú‚îÄ‚îÄ templates/           # Templates HTML Flask
‚îÇ   ‚îî‚îÄ‚îÄ index.html       # Page principale de l'application
‚îú‚îÄ‚îÄ static/              # Fichiers statiques (CSS, JS, images)
‚îú‚îÄ‚îÄ test/               # Tests unitaires et d'int√©gration
‚îú‚îÄ‚îÄ app.py              # Point d'entr√©e de l'application Flask
‚îú‚îÄ‚îÄ Dockerfile          # Configuration Docker
‚îú‚îÄ‚îÄ docker-compose.yml  # Orchestration Docker Compose
‚îú‚îÄ‚îÄ docker-build.sh     # Script de d√©ploiement Docker
‚îú‚îÄ‚îÄ .dockerignore       # Fichiers exclus du build Docker
‚îú‚îÄ‚îÄ env.example         # Exemple de variables d'environnement
‚îú‚îÄ‚îÄ pyproject.toml      # Configuration du projet et d√©pendances
‚îú‚îÄ‚îÄ DOCKER.md           # Documentation Docker
‚îî‚îÄ‚îÄ README.md           # Documentation du projet
```

## üê≥ D√©ploiement avec Docker (Recommand√©)

### Pr√©requis

- Docker install√© sur votre machine
- Variables d'environnement configur√©es (optionnel)

### D√©ploiement Rapide

#### Option 1: Script automatique

```bash
# Cloner le repository
git clone https://github.com/MamadouBousso/promptmulti_ia_docker.git
cd promptmulti_ia_docker

# Rendre le script ex√©cutable
chmod +x docker-build.sh

# Lancer le script
./docker-build.sh
```

#### Option 2: Docker Compose (recommand√©)

```bash
# Cloner le repository
git clone https://github.com/MamadouBousso/promptmulti_ia_docker.git
cd promptmulti_ia_docker

# Construire et lancer avec docker-compose
docker-compose up -d

# Voir les logs
docker-compose logs -f

# Arr√™ter
docker-compose down
```

#### Option 3: Docker manuel

```bash
# Cloner le repository
git clone https://github.com/MamadouBousso/promptmulti_ia_docker.git
cd promptmulti_ia_docker

# Construire l'image
docker build -t promptmulti_ia_docker .

# Lancer le conteneur
docker run -d \
  --name promptmulti_ia_docker-container \
  -p 8000:8000 \
  -e OPENAI_API_KEY="votre_cl√©_openai" \
  -e ANTHROPIC_API_KEY="votre_cl√©_claude" \
  -e GROQ_API_KEY="votre_cl√©_groq" \
  promptmulti_ia_docker
```

### Configuration des variables d'environnement

#### Option 1: Fichier .env

Cr√©ez un fichier `.env` √† la racine du projet :

```env
OPENAI_API_KEY=votre_cl√©_openai_ici
ANTHROPIC_API_KEY=votre_cl√©_claude_ici
GROQ_API_KEY=votre_cl√©_groq_ici
```

Puis lancez avec :

```bash
docker-compose --env-file .env up -d
```

#### Option 2: Variables d'environnement syst√®me

```bash
export OPENAI_API_KEY="votre_cl√©_openai"
export ANTHROPIC_API_KEY="votre_cl√©_claude"
export GROQ_API_KEY="votre_cl√©_groq"
```

### Acc√®s √† l'application

Une fois le conteneur lanc√©, l'application est accessible sur :
- **URL locale** : http://localhost:8000 (ou le port configur√©)
- **URL r√©seau** : http://votre_ip:8000

## üöÄ Installation Locale (Sans Docker)

### Pr√©requis

- Python 3.12+
- uv (gestionnaire de paquets Python)
- Cl√©s API pour au moins un des fournisseurs d'IA

### Installation

1. **Cloner le repository**
   ```bash
   git clone https://github.com/MamadouBousso/promptmulti_ia_docker.git
   cd promptmulti_ia_docker
   ```

2. **Initialiser l'environnement virtuel avec uv**
   ```bash
   uv venv .venv
   source .venv/bin/activate  # Sur macOS/Linux
   # ou
   .venv\Scripts\activate     # Sur Windows
   ```

3. **Installer les d√©pendances**
   ```bash
   uv pip install flask openai anthropic groq python-dotenv
   ```

4. **Configurer les variables d'environnement**
   ```bash
   # Copier le fichier d'exemple
   cp env.example .env
   
   # √âditer le fichier .env et ajouter vos cl√©s API
   # Voir la section Configuration des APIs ci-dessous
   ```

5. **Lancer l'application**
   ```bash
   python app.py
   ```

6. **Acc√©der √† l'application**
   Ouvrez votre navigateur et allez √† `http://localhost:8000`

## üîë Configuration des APIs

### Obtenir les cl√©s API

#### OpenAI (GPT-4o)
1. Allez sur [OpenAI Platform](https://platform.openai.com/)
2. Cr√©ez un compte ou connectez-vous
3. Allez dans la section "API Keys"
4. Cr√©ez une nouvelle cl√© API
5. Copiez la cl√© et ajoutez-la dans votre fichier `.env`

#### Claude (Anthropic)
1. Allez sur [Anthropic Console](https://console.anthropic.com/)
2. Cr√©ez un compte ou connectez-vous
3. Allez dans la section "API Keys"
4. Cr√©ez une nouvelle cl√© API
5. Copiez la cl√© et ajoutez-la dans votre fichier `.env`

#### Groq (Llama)
1. Allez sur [Groq Console](https://console.groq.com/)
2. Cr√©ez un compte ou connectez-vous
3. Allez dans la section "API Keys"
4. Cr√©ez une nouvelle cl√© API
5. Copiez la cl√© et ajoutez-la dans votre fichier `.env`

### Variables d'Environnement

Cr√©ez un fichier `.env` √† la racine du projet :

```env
# Configuration OpenAI (GPT-4o)
OPENAI_API_KEY=sk-your-actual-openai-api-key-here

# Configuration Anthropic (Claude)
ANTHROPIC_API_KEY=sk-ant-your-actual-anthropic-api-key-here

# Configuration Groq (Llama)
GROQ_API_KEY=gsk-your-actual-groq-api-key-here

# Configuration Flask
FLASK_ENV=development
FLASK_DEBUG=True
FLASK_PORT=8000
```

**Note** : Vous n'avez besoin que d'une seule cl√© API pour commencer. L'application fonctionnera avec les fournisseurs configur√©s.

## üéØ Utilisation

### Interface Utilisateur

L'interface se compose de :

1. **S√©lecteur d'IA** : Choisissez entre OpenAI, Claude, Groq ou comparer tous
2. **S√©lecteur de Mod√®le Groq** : Choisissez le mod√®le Llama sp√©cifique (visible uniquement pour Groq)
3. **Zone de saisie** : Champ de texte pour entrer vos questions/prompts
4. **Bouton d'envoi** : Pour soumettre votre requ√™te
5. **Zone de r√©ponse** : Affichage de la r√©ponse avec formatage markdown
6. **Zone de comparaison** : Affichage c√¥te √† c√¥te des r√©ponses des trois mod√®les
7. **Indicateur de chargement** : Animation pendant la g√©n√©ration
8. **Zone d'erreur** : Affichage des messages d'erreur

### Fonctionnement

1. **S√©lection du fournisseur** : Choisissez OpenAI, Claude, Groq ou "Comparer tous"
2. **S√©lection du mod√®le** : Si vous choisissez Groq, s√©lectionnez le mod√®le Llama
3. **Saisie du prompt** : Entrez votre question dans le champ de texte
4. **Envoi** : Cliquez sur "Envoyer" ou appuyez sur Entr√©e
5. **Affichage** : La r√©ponse s'affiche avec un formatage markdown complet

### Mod√®les Disponibles

#### Groq (Llama)
- **Llama 3.1 8B** : Mod√®le rapide et efficace
- **Llama 3.1 70B** : Mod√®le plus puissant
- **Llama 4 Scout 13B** : Mod√®le √©quilibr√©
- **Llama 4 Scout 17B** : Mod√®le performant
- **Llama 4 Scout 32B** : Mod√®le haute performance
- **Llama 4 Scout 65B** : Mod√®le ultra-performant

## üìù API Documentation

### Routes Disponibles

#### GET `/`
- **Description** : Page principale avec l'interface utilisateur
- **M√©thodes** : GET
- **R√©ponse** : Page HTML avec formulaire et interface

#### POST `/api/chat`
- **Description** : API endpoint pour les appels OpenAI
- **M√©thodes** : POST
- **Content-Type** : application/json
- **Param√®tres** :
  ```json
  {
    "prompt": "Votre question ici"
  }
  ```
- **R√©ponse** :
  ```json
  {
    "success": true,
    "text": "R√©ponse g√©n√©r√©e par OpenAI",
    "model": "gpt-4o"
  }
  ```

#### POST `/api/claude`
- **Description** : API endpoint pour les appels Claude
- **M√©thodes** : POST
- **Content-Type** : application/json
- **Param√®tres** :
  ```json
  {
    "prompt": "Votre question ici"
  }
  ```
- **R√©ponse** :
  ```json
  {
    "success": true,
    "text": "R√©ponse g√©n√©r√©e par Claude",
    "model": "claude-3-5-sonnet-20241022"
  }
  ```

#### POST `/api/groq`
- **Description** : API endpoint pour les appels Groq
- **M√©thodes** : POST
- **Content-Type** : application/json
- **Param√®tres** :
  ```json
  {
    "prompt": "Votre question ici",
    "model": "llama3-8b-8192"
  }
  ```
- **R√©ponse** :
  ```json
  {
    "success": true,
    "text": "R√©ponse g√©n√©r√©e par Groq",
    "model": "llama3-8b-8192"
  }
  ```

#### POST `/api/compare`
- **Description** : API endpoint pour comparer les trois mod√®les
- **M√©thodes** : POST
- **Content-Type** : application/json
- **Param√®tres** :
  ```json
  {
    "prompt": "Votre question ici"
  }
  ```
- **R√©ponse** :
  ```json
  {
    "success": true,
    "prompt": "Votre question ici",
    "responses": {
      "openai": {
        "success": true,
        "text": "R√©ponse OpenAI",
        "model": "gpt-4o"
      },
      "claude": {
        "success": true,
        "text": "R√©ponse Claude",
        "model": "claude-3-5-sonnet-20241022"
      },
      "groq": {
        "success": true,
        "text": "R√©ponse Groq",
        "model": "llama3-8b-8192"
      }
    }
  }
  ```

## üìã Commandes Docker Utiles

### Gestion des conteneurs

```bash
# Voir les conteneurs en cours
docker ps

# Voir les logs
docker logs promptmulti_ia_docker-container

# Arr√™ter le conteneur
docker stop promptmulti_ia_docker-container

# Red√©marrer le conteneur
docker restart promptmulti_ia_docker-container

# Supprimer le conteneur
docker rm promptmulti_ia_docker-container

# Supprimer l'image
docker rmi promptmulti_ia_docker
```

### Avec Docker Compose

```bash
# Voir les services
docker-compose ps

# Voir les logs
docker-compose logs -f app

# Red√©marrer le service
docker-compose restart app

# Arr√™ter et supprimer
docker-compose down

# Reconstruire l'image
docker-compose build --no-cache
```

## üîç D√©pannage

### Probl√®mes Docker

#### Probl√®me de port d√©j√† utilis√©
Si le port 8000 est d√©j√† utilis√©, changez-le dans `docker-compose.yml` :
```yaml
ports:
  - "8080:8000"  # Port externe:Port interne
```

#### Probl√®me de permissions
```bash
# Donner les bonnes permissions au script
chmod +x docker-build.sh
```

#### Reconstruire l'image
```bash
# Supprimer l'ancienne image
docker rmi promptmulti_ia_docker

# Reconstruire
docker build -t promptmulti_ia_docker .
```

#### V√©rifier les logs
```bash
# Logs en temps r√©el
docker logs -f promptmulti_ia_docker-container

# Derniers logs
docker logs --tail 50 promptmulti_ia_docker-container
```

### Probl√®mes G√©n√©raux

#### Erreur "API non disponible"
- V√©rifiez que vos cl√©s API sont correctement configur√©es
- Assurez-vous que les variables d'environnement sont d√©finies
- V√©rifiez la validit√© de vos cl√©s API

#### Erreur de connexion
- V√©rifiez que l'application est bien lanc√©e
- V√©rifiez le port utilis√© (8000 par d√©faut)
- V√©rifiez les logs pour plus de d√©tails

## ü§ù Contribution

Les contributions sont les bienvenues ! Voici comment contribuer :

1. **Fork** le projet
2. **Cr√©ez** une branche pour votre fonctionnalit√© (`git checkout -b feature/AmazingFeature`)
3. **Commitez** vos changements (`git commit -m 'Add some AmazingFeature'`)
4. **Poussez** vers la branche (`git push origin feature/AmazingFeature`)
5. **Ouvrez** une Pull Request

## üìÑ Licence

Ce projet est sous licence MIT. Voir le fichier `LICENSE` pour plus de d√©tails.

## üë®‚Äçüíª Auteur

**Mamadou Bousso**
- GitHub: [@MamadouBousso](https://github.com/MamadouBousso)
- Email: mamadou.bousso@example.com

## üôè Remerciements

- [OpenAI](https://openai.com/) pour l'API GPT-4o
- [Anthropic](https://www.anthropic.com/) pour l'API Claude
- [Groq](https://groq.com/) pour l'API Llama
- [Flask](https://flask.palletsprojects.com/) pour le framework web
- [Tailwind CSS](https://tailwindcss.com/) pour le styling
- [uv](https://github.com/astral-sh/uv) pour la gestion des d√©pendances Python

## üìû Support

Si vous rencontrez des probl√®mes ou avez des questions :

1. Consultez la section [D√©pannage](#d√©pannage)
2. V√©rifiez les [Issues](https://github.com/MamadouBousso/promptmulti_ia_docker/issues) existantes
3. Cr√©ez une nouvelle [Issue](https://github.com/MamadouBousso/promptmulti_ia_docker/issues/new) si n√©cessaire

---

**‚≠ê N'oubliez pas de donner une √©toile au projet si vous l'aimez !**
