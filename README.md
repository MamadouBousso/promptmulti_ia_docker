# PromptMulti_IA Docker

Un assistant multi-IA intelligent dÃ©veloppÃ© avec Flask et une interface web moderne utilisant Tailwind CSS, intÃ©grant les APIs OpenAI (GPT-4o), Claude (Anthropic) et Groq (Llama) pour des rÃ©ponses intelligentes et comparatives. **Version DockerisÃ©e avec historique des conversations.**

## ğŸ“‹ Description

PromptMulti_IA Docker est une application web complÃ¨te qui permet aux utilisateurs d'interagir avec plusieurs assistants IA via un formulaire textuel. L'application supporte trois fournisseurs d'IA majeurs et permet de comparer leurs rÃ©ponses en temps rÃ©el. **L'application est entiÃ¨rement containerisÃ©e avec Docker et inclut un systÃ¨me d'historique des conversations persistant.**

## ğŸš€ FonctionnalitÃ©s

### ğŸ¤– **Multi-IA Support**
- **OpenAI (GPT-4o)** : IntÃ©gration complÃ¨te avec l'API OpenAI
- **Claude (Anthropic)** : Support de Claude 3.5 Sonnet
- **Groq (Llama)** : Support de multiples modÃ¨les Llama (3.1 8B, 70B, 4 Scout)
- **Mode Comparaison** : Comparaison simultanÃ©e des rÃ©ponses des trois fournisseurs

### ğŸ’¾ **SystÃ¨me d'Historique**
- **Base de donnÃ©es SQLite** : Stockage persistant des conversations
- **Recherche avancÃ©e** : Recherche par mot-clÃ© dans l'historique
- **Statistiques en temps rÃ©el** : MÃ©triques d'utilisation et de performance
- **Gestion des conversations** : Visualisation, suppression, dÃ©tails complets
- **MÃ©tadonnÃ©es enrichies** : Temps de rÃ©ponse, tokens utilisÃ©s, modÃ¨les

### ğŸ¨ **Interface Utilisateur**
- **Design moderne** : Interface responsive avec Tailwind CSS
- **Rendu Markdown** : Support complet du formatage Markdown
- **Mode sombre/clair** : Interface adaptative
- **Indicateurs de chargement** : Feedback visuel en temps rÃ©el
- **Gestion d'erreurs** : Messages d'erreur clairs et informatifs

### ğŸ³ **Containerisation Docker**
- **DÃ©ploiement simplifiÃ©** : Une seule commande pour lancer l'application
- **Volumes persistants** : Base de donnÃ©es et fichiers de configuration
- **Variables d'environnement** : Configuration sÃ©curisÃ©e des clÃ©s API
- **Docker Compose** : Orchestration complÃ¨te avec health checks

## ğŸ› ï¸ Installation et Configuration

### PrÃ©requis
- Docker et Docker Compose installÃ©s
- ClÃ©s API pour au moins un fournisseur IA (OpenAI, Claude, ou Groq)

### 1. Cloner le dÃ©pÃ´t
```bash
git clone https://github.com/MamadouBousso/promptmulti_ia_docker.git
cd promptmulti_ia_docker
```

### 2. Configurer les clÃ©s API
```bash
# Copier le fichier d'exemple
cp env.example .env

# Ã‰diter le fichier .env avec vos clÃ©s API
nano .env
```

**ClÃ©s API requises :**
- `OPENAI_API_KEY` : Obtenez sur [OpenAI Platform](https://platform.openai.com/api-keys)
- `ANTHROPIC_API_KEY` : Obtenez sur [Anthropic Console](https://console.anthropic.com/)
- `GROQ_API_KEY` : Obtenez sur [Groq Console](https://console.groq.com/)

### 3. Lancer l'application

#### Option A : Docker Compose (RecommandÃ©)
```bash
docker-compose up -d
```

#### Option B : Docker manuel
```bash
# Construire l'image
docker build -t promptmulti_ia_docker .

# Lancer le conteneur
docker run -d \
  --name promptmulti_ia_docker-container \
  -p 9000:8000 \
  -v $(pwd)/data:/app/data \
  --env-file .env \
  promptmulti_ia_docker
```

#### Option C : Script automatisÃ©
```bash
chmod +x docker-build.sh
./docker-build.sh
```

### 4. AccÃ©der Ã  l'application
Ouvrez votre navigateur et allez sur : **http://localhost:9000**

## ğŸ“Š Utilisation

### Interface Principale
1. **Choisissez un fournisseur IA** : OpenAI, Claude, Groq, ou "Comparer tous"
2. **Saisissez votre question** dans le champ de texte
3. **Cliquez sur "Envoyer"** pour obtenir une rÃ©ponse
4. **Consultez l'historique** en bas de page

### FonctionnalitÃ©s AvancÃ©es
- **Recherche** : Utilisez la barre de recherche pour trouver des conversations
- **Statistiques** : Consultez les mÃ©triques d'utilisation en temps rÃ©el
- **DÃ©tails** : Cliquez sur "Voir" pour afficher les dÃ©tails d'une conversation
- **Suppression** : Supprimez les conversations inutiles

### API REST
L'application expose plusieurs endpoints API :

```bash
# Historique des conversations
GET /api/history

# DÃ©tails d'une conversation
GET /api/history/{id}

# Recherche dans l'historique
GET /api/history/search?q={term}

# Statistiques
GET /api/stats

# Supprimer une conversation
DELETE /api/history/{id}

# Nettoyer l'historique ancien
POST /api/cleanup
```

## ğŸ—ï¸ Architecture

```
promptmulti_ia_docker/
â”œâ”€â”€ app.py                 # Application Flask principale
â”œâ”€â”€ Dockerfile            # Configuration Docker
â”œâ”€â”€ docker-compose.yml    # Orchestration Docker
â”œâ”€â”€ .env                  # Variables d'environnement
â”œâ”€â”€ src/
â”‚   â””â”€â”€ infrastructure/
â”‚       â”œâ”€â”€ database.py   # Gestionnaire de base de donnÃ©es SQLite
â”‚       â”œâ”€â”€ openai_client.py
â”‚       â”œâ”€â”€ claude_client.py
â”‚       â””â”€â”€ groq_client.py
â”œâ”€â”€ templates/
â”‚   â””â”€â”€ index.html        # Interface utilisateur
â”œâ”€â”€ static/
â”‚   â”œâ”€â”€ css/
â”‚   â”‚   â””â”€â”€ styles.css
â”‚   â””â”€â”€ js/
â”‚       â””â”€â”€ app.js        # Logique frontend
â””â”€â”€ data/                 # Base de donnÃ©es SQLite (volume Docker)
```

## ğŸ”§ Configuration AvancÃ©e

### Variables d'Environnement
```bash
# Configuration Flask
FLASK_ENV=production
FLASK_PORT=8000

# ModÃ¨les par dÃ©faut
OPENAI_MODEL="gpt-4o"
CLAUDE_MODEL="claude-3-5-sonnet-20241022"
GROQ_MODEL="llama3-8b-8192"

# ParamÃ¨tres de gÃ©nÃ©ration
MAX_TOKENS=500
TEMPERATURE=0.7
```

### Base de DonnÃ©es
L'application utilise SQLite pour stocker :
- **Conversations** : prompts, timestamps, modÃ¨les utilisÃ©s
- **RÃ©ponses** : textes, mÃ©tadonnÃ©es, temps de rÃ©ponse, tokens
- **Statistiques** : mÃ©triques d'utilisation et de performance

### SÃ©curitÃ©
- Les clÃ©s API sont stockÃ©es dans des variables d'environnement
- Le fichier `.env` est exclu du dÃ©pÃ´t Git
- Validation des entrÃ©es utilisateur
- Gestion sÃ©curisÃ©e des erreurs

## ğŸ“ˆ Statistiques et Monitoring

L'application fournit des statistiques dÃ©taillÃ©es :
- **Total des conversations**
- **Taux de succÃ¨s**
- **Conversations par jour**
- **Performance par fournisseur**
- **Utilisation des tokens**

## ğŸ› DÃ©pannage

### ProblÃ¨mes Courants

**1. Clients IA non disponibles**
```bash
# VÃ©rifiez que les clÃ©s API sont configurÃ©es
cat .env | grep API_KEY
```

**2. Port dÃ©jÃ  utilisÃ©**
```bash
# Changez le port dans docker-compose.yml
ports:
  - "9001:8000"  # Au lieu de 9000:8000
```

**3. Base de donnÃ©es corrompue**
```bash
# Supprimez et recrÃ©ez le volume
docker-compose down
rm -rf data/
docker-compose up -d
```

**4. ProblÃ¨mes de permissions**
```bash
# Donnez les bonnes permissions au dossier data
chmod 755 data/
```

## ğŸ¤ Contribution

Les contributions sont les bienvenues ! Pour contribuer :

1. Fork le projet
2. CrÃ©ez une branche pour votre fonctionnalitÃ©
3. Committez vos changements
4. Poussez vers la branche
5. Ouvrez une Pull Request

## ğŸ“„ Licence

Ce projet est sous licence MIT. Voir le fichier `LICENSE` pour plus de dÃ©tails.

## ğŸ™ Remerciements

- **OpenAI** pour GPT-4o
- **Anthropic** pour Claude
- **Groq** pour l'accÃ¨s aux modÃ¨les Llama
- **Flask** pour le framework web
- **Tailwind CSS** pour le design
- **SQLite** pour la base de donnÃ©es

## ğŸ“ Support

Pour toute question ou problÃ¨me :
- Ouvrez une issue sur GitHub
- Consultez la documentation dans le code
- VÃ©rifiez les logs Docker : `docker logs promptmulti_ia_docker-container`

---

**ğŸ¯ Application prÃªte pour la production avec toutes les fonctionnalitÃ©s avancÃ©es !**
